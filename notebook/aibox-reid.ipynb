{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Xilinx Logo](images/xilinx_logo.png \"Xilinx Logo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction:\n",
    "\n",
    "This notebook demonstrates how to use up to 4 channels **1080p H264/H265** of RTSP video streams or local video file source, and perform pedestrian detection with Refinedet models and ReID and tracking on each channel, finally display the images with pedestrain bounding boxes and ReID labels on the 4K monitors with a 2x2 layout.\n",
    "\n",
    "\n",
    "**Note** For security reasons, the Jupyter Lab Server should not be started as root user, but because of Linux kernel constraints, this restriction causes this Jupyter notebook can only display one channel video, this restriction may be removed later with Linux kernel update.\n",
    "\n",
    "**Note** If you want to run with multiple channels, please switch to the command line aibox-reid application.\n",
    "\n",
    "\n",
    "The application is based on the VVAS (Vitis Video Analytics SDK) framework, also utilizing the open source GStreamer plugins.\n",
    "\n",
    "Vitis Video Analytics SDK (VVAS) is developed by Xilinx to provide many useful GStreamer plugins as the middleware between the application and underlying FPGA acclerators, including DPU AI inference engine, and other PL accelerators such as the one for AI input preprocessing.\n",
    "\n",
    "Please refer to the [Kria™ KV260 Vision AI Starter Kit Applications GitHub Pages](https://xilinx.github.io/kria-apps-docs/index.html) for detailed HW/SW architecture and [Vitis Video Analytics SDK GitHub Pages](https://xilinx.github.io/VVAS/#) for the VVAS related info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Initialization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preapare Data to Visualize the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory for saving the pipeline graph as dot file.\n",
    "\n",
    "Set the GStreamer debug dot directory environment variable to point to that directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb=\"aibox-reid\"\n",
    "dotdir = \"/tmp/gst-dot/\" + nb + \"/\"\n",
    "!mkdir -p $dotdir\n",
    "%env GST_DEBUG_DUMP_DOT_DIR = $dotdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all python modules required for this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import system, util modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import subprocess\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Add some util path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathv=\"{}:/usr/sbin:/sbin\".format(os.getenv(\"PATH\"))\n",
    "%env PATH = $pathv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GStreamer related library import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "gi.require_version(\"GstApp\", \"1.0\")\n",
    "gi.require_version('GstVideo', '1.0')\n",
    "gi.require_version('GIRepository', '2.0')\n",
    "from gi.repository import GObject, GLib, Gst, GstVideo, GLib, GIRepository\n",
    "Gst.init(None)\n",
    "Gst.debug_set_threshold_from_string('*:1', True)\n",
    "\n",
    "confdir=\"/opt/xilinx/kv260-aibox-reid/share/vvas\"\n",
    "pip=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixer setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo | modetest -M xlnx -D 80000000.v_mix -s 52@40:3840x2160@NV16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Construct the Pipeline and Run Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Notice*** After run the application, please \"Shut Down\" or \"Restart\" the kernel of this notebook, otherwise the process will keep occupying the DPU device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Option to set the RTSP stream URLs or video file location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RTSP input\n",
    "\n",
    "  You can normally get or configure in the Admin page of your IP camera.\n",
    "\n",
    "  Such as: rtsp://ip-address:port/name \n",
    "  \n",
    "  When you get it, you may first verify if it's playable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* File input\n",
    "\n",
    "   \n",
    "    To demonstrate the application in the case where no IP camera is available, a video source may be played from a file on the SD card instead.\n",
    "  \n",
    "    You can download video files from the following links, which is of MP4 format.\n",
    "\n",
    "    Demo video:\n",
    "\n",
    "    * https://pixabay.com/videos/liverpool-people-couple-pier-head-46090/\n",
    "    * https://pixabay.com/videos/liverpool-pier-head-england-uk-46098/\n",
    "    * https://pixabay.com/videos/spring-walk-park-trees-flowers-15252/\n",
    "    * https://pixabay.com/videos/walking-people-city-bucharest-6099/\n",
    "\n",
    "    Then you need to transcode it to H264 file which is the supported input format.\n",
    "\n",
    "    > ffmpeg -i input-video.mp4 -c:v libx264 -pix_fmt nv12 -r 30 output.nv12.h264\n",
    "\n",
    "    Finally, please upload or copy these transcoded H264 files to the board, place it to somewhere under /tmp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** For security reasons, Jupyter Lab server should not be started as root user, but because of Linux kernel constraints, this restriction causes this Jupyter notebook can only display one channel video.\n",
    "\n",
    "So though the below variable *aitask* is to configure multiple input channels, only one channel could be displayed. Please  use the command line aibox-reid application to run multiple channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The var ***aitask*** is an array of tuple, of which each corresponds to one channel.\n",
    "\n",
    "\n",
    "In each tuple in the array:\n",
    "\n",
    "* The 1st value: The position of the channel\n",
    "\n",
    "    0: TopLeft, 1: TopRight, 2: Bottom Left, 3: Bottom Right\n",
    "    \n",
    "* The 2nd value: The string of either the RTSP URL, or path to local video file\n",
    "\n",
    "* The 3rd value: The encoding type of the video file, only support h264/h265.\n",
    "\n",
    "* The 4th value: \"rtsp\" or \"file\" indicating the source type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"/root/walking-people.nv12.30fps.1080p.h264\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aitask=[ \\\n",
    "#        (0, url, \"h264\", \"rtsp\"), \\\n",
    "        (1,file, \"h264\", \"file\"), \\\n",
    "#        (2, url, \"h264\", \"rtsp\"), \\\n",
    "#        (3,file, \"h264\", \"file\") \\\n",
    "       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Pipeline for the First Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "pos=aitask[0][0]\n",
    "url=aitask[0][1]\n",
    "fmt=aitask[0][2]\n",
    "src=aitask[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if src == \"file\":\n",
    "    if not os.path.isfile(url):\n",
    "        print(\"The video file {} doesn't exist.\".format(url))\n",
    "        assert(False)\n",
    "    pip += \"multifilesrc location=\\\"{}\\\" \".format(url)\n",
    "    que = \"\"\n",
    "elif src == \"rtsp\":\n",
    "    pip += \"rtspsrc location=\\\"{}\\\" ! queue ! rtp{}depay ! queue \".format(url, fmt)\n",
    "    que = \" ! queue max-size-buffers=2 leaky=2 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip += \"! {fmt}parse ! queue ! omx{fmt}dec ! video/x-raw, format=NV12 {que} \".format(fmt=fmt, que=que)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Do the color conversion and preprocess to the pedestrian detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip += \" ! tee name=t{ind} t{ind}.src_0 ! queue \\\n",
    "! vvas_xmultisrc kconfig=\\\"{conf}/ped_pp.json\\\" \".format(ind=i, conf=confdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform pedestrain detection with refinedet models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip += \" ! queue ! vvas_xfilter name=refinedet_{ind} kernels-config=\\\"{conf}/refinedet.json\\\" \".format(ind=i, conf=confdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Crop the detected pedestrain into multiple buffer, and pass it down with inference meta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip += \" ! queue ! vvas_xfilter name=crop_{ind} kernels-config=\\\"{conf}/crop.json\\\" \".format(ind=i, conf=confdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Perform ReID on the previously cropped object to get character, and track it with dedicated ReID Tracker algorithm.\n",
    "\n",
    "Here ReID is done on DPU, and tracker on ARM, both of them is done in this plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip += \" ! queue ! vvas_xfilter name=reid_{ind} kernels-config=\\\"{conf}/reid.json\\\" \".format(ind=i, conf=confdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pass inference meta of the scaled image to vvas_xmetaaffixer, to be scaled back to the original input buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip += \" ! queue ! scalem{ind}.sink_master vvas_xmetaaffixer name=scalem{ind} scalem{ind}.src_master ! fakesink \".format(ind=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Connect the original input buffer to vvas_xmetaaffixer to get the inference meta by scaling the meta from previous one, then draw the bbox and identity on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip += \" t{ind}.src_1 ! queue ! scalem{ind}.sink_slave_0 scalem{ind}.src_slave_0 \\\n",
    "! queue ! vvas_xfilter kernels-config=\\\"{conf}/draw_reid.json\\\" \".format(ind=i, conf=confdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pass to mixer to be rendered on 1/4 of 4K screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip += \" ! kmssink bus-id=b0000000.v_mix plane-id={pid} render-rectangle=\\\"<{w},{h},1920,1080>\\\" show-preroll-frame=false sync=false can-scale=false  \". \\\n",
    "format(pid=34+i, w=pos%2*1920, h=pos//2*1080) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap above one channel pipeline creation to one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_channel_pipe(i):\n",
    "    global pip\n",
    "    pos=aitask[i][0]\n",
    "    url=aitask[i][1]\n",
    "    fmt=aitask[i][2]\n",
    "    src=aitask[i][3]\n",
    "\n",
    "    if src == \"file\":\n",
    "        if not os.path.isfile(url):\n",
    "            print(\"The video file {} doesn't exist.\", url)\n",
    "            assert(False)\n",
    "        pip += \"multifilesrc location=\\\"{}\\\" \".format(url)\n",
    "        que = \"\"\n",
    "    elif src == \"rtsp\":\n",
    "        pip += \"rtspsrc location=\\\"{}\\\" ! queue ! rtp{}depay ! queue \".format(url, fmt)    \n",
    "        que = \" ! queue max-size-buffers=2 leaky=2 \"        \n",
    "    pip += \"! {fmt}parse ! queue ! omx{fmt}dec ! video/x-raw, format=NV12 {que} \".format(fmt=fmt, que=que)\n",
    "    pip += \" ! tee name=t{ind} t{ind}.src_0 ! queue ! vvas_xmultisrc kconfig=\\\"{conf}/ped_pp.json\\\" \".format(ind=i, conf=confdir)\n",
    "    pip += \" ! queue ! vvas_xfilter name=refinedet_{ind} kernels-config=\\\"{conf}/refinedet.json\\\" \".format(ind=i, conf=confdir)\n",
    "    pip += \" ! queue ! vvas_xfilter name=crop_{ind} kernels-config=\\\"{conf}/crop.json\\\" \".format(ind=i, conf=confdir)\n",
    "    pip += \" ! queue ! vvas_xfilter name=reid_{ind} kernels-config=\\\"{conf}/reid.json\\\" \".format(ind=i, conf=confdir)\n",
    "    pip += \" ! queue ! scalem{ind}.sink_master vvas_xmetaaffixer name=scalem{ind} scalem{ind}.src_master ! fakesink \".format(ind=i)\n",
    "    pip += \" t{ind}.src_1 ! queue ! scalem{ind}.sink_slave_0 scalem{ind}.src_slave_0 \\\n",
    "    ! queue ! vvas_xfilter kernels-config=\\\"{conf}/draw_reid.json\\\" \".format(ind=i, conf=confdir)\n",
    "    pip += \" ! kmssink bus-id=b0000000.v_mix plane-id={pid} render-rectangle=\\\"<{w},{h},1920,1080>\\\" show-preroll-frame=false sync=false \". \\\n",
    "    format(pid=34+i, w=pos%2*1920, h=pos//2*1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, min(4,len(aitask))):\n",
    "    One_channel_pipe(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run the Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Gst.parse_launch(pip)\n",
    "pipe.set_state(Gst.State.PLAYING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. View the GStreamer Pipeline Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dump dot file of pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gst.debug_bin_to_dot_file(pipe, Gst.DebugGraphDetails.ALL, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert the dot file to png and display the pipeline graph.\n",
    "\n",
    "    The image will be displayed bellow the following code cell.\n",
    "\n",
    "    **Note**: This step may take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from IPython.display import Image, display, clear_output\n",
    "dotfile = dotdir + \"/\" + nb + \".dot\"\n",
    "\n",
    "print(\"Converting dot to graph...\")\n",
    "graph = pydot.graph_from_dot_file(dotfile, 'utf-8')\n",
    "print(\"Conversion done.\")\n",
    "display(Image(graph[0].create(None,'png', 'utf-8')))\n",
    "print(\"Pipeline graph is shown, double click it to zoom in and out.\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After the pipeline dot graph is shown in the previous step, the process can be interrupted by clicking the stop square button on the Jupyter toolbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = GLib.MainLoop()\n",
    "try:\n",
    "    loop.run()\n",
    "except:\n",
    "    sys.stdout.write(\"Interrupt caught\\n\")\n",
    "    pipe.set_state(Gst.State.NULL)\n",
    "    loop.quit()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Summary\n",
    "The Jupyter application shows how to:\n",
    "\n",
    "Create a GStreamer pipeline that accepts up to 4 channels of RTSP streams, utilizes the VVAS framework to call Vitis AI Library to do pedestrian detection, ReID and tracking on the incoming frames, and draw bounding boxes and ID of detected results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Copyright© 2021 Xilinx</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
